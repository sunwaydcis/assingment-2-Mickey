// MainApp.scala
object MainApp {

  /**
   * Main entry point demonstrating proper collection workflow:
   * 1. File discovery â†’ 2. Data loading â†’ 3. Analysis pipeline
   * Uses Option/validation patterns common in Scala collections.
   */
  def main(args: Array[String]): Unit = {
    println("ðŸ¨ HOTEL BOOKING DATA ANALYSIS")
    println("=" * 70)

    // Using utility method to find file (returns Option-like behavior)
    val file = DataUtils.findDatasetFile()

    // Early validation pattern - prevents processing invalid data
    if (!file.exists()) {
      println("âŒ Error: Hotel_Dataset.csv not found!")
      println("\nðŸ’¡ Please place Hotel_Dataset.csv in the project root folder")
      return
    }

    println(s"âœ… Found dataset: ${file.getAbsolutePath}")


    println("\nðŸ“‚ Loading data...")
    // Loads data into List[HotelBooking] - fundamental collection type
    val bookings = DataUtils.loadHotelData(file.getAbsolutePath)

    // isEmpty check for safe processing
    if (bookings.isEmpty) {
      println("âŒ Failed to load booking data. Cannot proceed.")
      return
    }

    // Delegates to analysis method with immutable collection
    runAnalysis(bookings)
  }

  /**
   * Showcases advanced collection operations in a clean, readable manner.
   * Each statistical line demonstrates a different collection transformation:
   * - map + toSet + size = unique count
   * - map + sum = aggregation
   * All operations maintain immutability and are side-effect free.
   */

  private def runAnalysis(bookings: List[HotelBooking]): Unit = {
    // Multiple collection transformations in concise expressions
    println(s"\nâœ… Successfully loaded ${bookings.size} booking records")
    println(s"ðŸ“Š Dataset Statistics:")

    // mapâ†’toSetâ†’size pattern for unique counting
    println(s"   â€¢ Unique hotels: ${bookings.map(_.hotelName).toSet.size}")
    // Reused pattern for different field
    println(s"   â€¢ Unique origin countries: ${bookings.map(_.originCountry).toSet.size}")
    // mapâ†’sum pattern with formatted output
    println(f"   â€¢ Total revenue: $$${bookings.map(_.bookingPrice).sum}%.2f")
    // Similar aggregation for visitor count
    println(f"   â€¢ Total visitors: ${bookings.map(_.noOfPeople).sum}")

    // Delegates to specialized analyzers - modular collection processing
    Question1Analyzer.analyze(bookings)
    Question2Analyzer.analyze(bookings)
    Question3Analyzer.analyze(bookings)

    // Show polymorphism explanation
    showPolymorphismExplanation()
  }

  private def showPolymorphismExplanation(): Unit = {
    println("\n" + "=" * 70)
    println("POLYMORPHISM IN COLLECTION API - EXPLANATION")
    println("=" * 70)

    println("""
TYPES OF POLYMORPHISM DEMONSTRATED:

1. PARAMETRIC POLYMORPHISM (Generics):
   â€¢ List[HotelBooking] - Type-safe collection that can hold HotelBooking objects
   â€¢ Map[String, Int] - Generic key-value pairs
   â€¢ Methods like groupBy[A], map[B], filter work with any data type

2. SUBTYPE POLYMORPHISM:
   â€¢ All Scala collections (List, Map, Set) implement common traits like Traversable
   â€¢ This allows uniform interfaces across different collection types

3. HIGHER-ORDER FUNCTIONS:
   â€¢ Functions that take other functions as parameters
   â€¢ Examples: bookings.map(_.hotelName), bookings.filter(_.bookingPrice > 100)

CONCRETE EXAMPLES FROM THIS PROGRAM:

1. bookings.groupBy(_.originCountry)
   â€¢ Returns: Map[String, List[HotelBooking]]
   â€¢ Polymorphism: groupBy works on any collection type and any element type

2. .mapValues(_.size)
   â€¢ Transforms each value in the Map without changing keys
   â€¢ Returns: Map[String, Int]

3. .maxBy(_._2)
   â€¢ Higher-order function that finds maximum based on a criterion
   â€¢ Uses lambda expression: _._2 means "second element of tuple"

4. bookings.map(_.bookingPrice).sum
   â€¢ map transforms HotelBooking â†’ Double
   â€¢ sum works on any numeric collection

BENEFITS OF THIS APPROACH:

â€¢ TYPE SAFETY: Compile-time checking prevents runtime errors
â€¢ CODE REUSABILITY: Same patterns work with different data types
â€¢ CONCISENESS: Fewer lines of code than imperative alternatives
â€¢ READABILITY: Declarative style clearly expresses intent
â€¢ COMPOSABILITY: Operations can be chained together

LIMITATIONS:

â€¢ LEARNING CURVE: Functional programming concepts take time to master
â€¢ DEBUGGING DIFFICULTY: Long chains can be hard to debug
â€¢ PERFORMANCE OVERHEAD: Some abstractions have runtime costs
â€¢ MEMORY USAGE: Intermediate collections in chains use more memory

WHY THIS APPROACH IS EFFECTIVE:

The use of polymorphic collection operations allows us to answer
complex business questions in just a few lines of code, making the
analysis both efficient and maintainable.
""")
  }
}